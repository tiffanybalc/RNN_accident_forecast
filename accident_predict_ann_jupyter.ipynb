{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from tensorflow.python.ops import rnn, rnn_cell\n",
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progressbar(cur,total):\n",
    "    percent = '{:.2%}'.format( float(cur)/total)\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write('[%-50s] %s' % ( '=' * int(math.floor(cur * 50 /total)),percent))\n",
    "    sys.stdout.flush()\n",
    "    if cur == total:\n",
    "        sys.stdout.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.session = tf.Session()\n",
    "        self.inputs = None\n",
    "        self.input_layer = None\n",
    "        self.label_layer = None\n",
    "        self.weights = None\n",
    "        self.biases = None\n",
    "        self.lstm_cell = None\n",
    "        self.prediction = None\n",
    "        self.loss = None\n",
    "        self.trainer = None\n",
    "        \n",
    "        #added from tensorflow\n",
    "        #self._is_training = is_training\n",
    "        #self._input = input_\n",
    "        self._rnn_params = None\n",
    "        self._cell = None\n",
    "        #self.batch_size = input_.batch_size\n",
    "        #self.num_steps = input_.num_steps\n",
    "        #size = config.hidden_size\n",
    "        #vocab_size = config.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def __del__(self):\n",
    "        self.session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def train(self, train_x, train_y, learning_rate=0.01, epochs=1, batch_n=1, input_n=1):\n",
    "        seq_n = len(train_x)\n",
    "        input_n = len(train_x[0])\n",
    "        output_n = len(train_y[0])\n",
    "        \n",
    "        self.inputs = tf.placeholder(tf.float32, [batch_n, input_n])\n",
    "        self.label_layer = tf.placeholder(tf.float32, [output_n])\n",
    "        self.input_layer = [tf.reshape(i, (1, input_n)) for i in tf.split(0, batch_n, self.inputs)]\n",
    "        \n",
    "        self.weights = tf.Variable(tf.random_normal([input_n, output_n]))\n",
    "        self.biases = tf.Variable(tf.random_normal([output_n]))\n",
    "        self.prediction = tf.matmul(self.inputs, self.weights) + self.biases\n",
    "        \n",
    "        \n",
    "        self.loss = tf.reduce_mean(tf.square(self.prediction - self.label_layer))\n",
    "        self.trainer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(self.loss)\n",
    "        \n",
    "        initer = tf.global_variables_initializer()\n",
    "        \n",
    "        writer = tf.summary.FileWriter(\"./graph\", self.session.graph)\n",
    "        \n",
    "        tf.scalar_summary(\"loss\", self.loss)\n",
    "        merged_summary = tf.merge_all_summaries()\n",
    "        self.session.run(initer)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            for idx in range(seq_n):\n",
    "                input_x = train_x[idx:idx+1]\n",
    "                output_y = train_y[idx]\n",
    "                feed_dict = {self.inputs: input_x, self.label_layer: output_y}\n",
    "                _, summary = self.session.run([self.trainer, merged_summary], feed_dict=feed_dict)\n",
    "\n",
    "                if False:\n",
    "                    cur_prediction = self.session.run(self.prediction, feed_dict=feed_dict)\n",
    "                    cur_loss = self.session.run(self.loss, feed_dict=feed_dict)\n",
    "                    print (cur_prediction[0][0], cur_loss)\n",
    "                \n",
    "                writer.add_summary(summary, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def predict(self, test_x, test_y, batch_n):\n",
    "        seq_n = len(test_x)\n",
    "        input_n = len(test_x[0])\n",
    "\n",
    "        acc_predict_cnt = 0\n",
    "        acc_cnt = 0\n",
    "        no_acc_predict_cnt = 0\n",
    "        no_acc_cnt = 0\n",
    "        for idx in range(seq_n):\n",
    "            input_x = test_x[idx:idx + batch_n]\n",
    "            label_y = test_y[idx]\n",
    "            predict_y = self.session.run(self.prediction, feed_dict={self.inputs: input_x})\n",
    "            if label_y >= 1.0:\n",
    "                acc_cnt += 1\n",
    "                if label_y == int(predict_y+0.5):\n",
    "                    acc_predict_cnt += 1\n",
    "            else:\n",
    "                no_acc_cnt += 1\n",
    "                if label_y == int(predict_y+0.5):\n",
    "                    no_acc_predict_cnt += 1\n",
    "\n",
    "\n",
    "        acc_accuracy = float(acc_predict_cnt)/acc_cnt\n",
    "        no_acc_accuracy = float(no_acc_predict_cnt)/no_acc_cnt\n",
    "\n",
    "        print(\"no_acc_predict_cnt=%d, acc_predict_cnt=%d\"%(no_acc_cnt, acc_cnt))\n",
    "        print(\"predict no_acc_predict_cnt=%d, acc_predict_cnt=%d\"%(no_acc_predict_cnt, acc_predict_cnt))\n",
    "        print(\"acc accuracy= %f\"% acc_accuracy)\n",
    "        print(\"no acc accuracy= %f\"% no_acc_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def test(self, train_x, train_y, test_x, test_y, batch_n, epochs):\n",
    "        self.train(train_x, train_y, batch_n=batch_n, epochs=epochs)\n",
    "        self.predict(test_x, test_y, batch_n=batch_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    return (x-min(x))/(max(x)-min(x))\n",
    "\n",
    "def data_import(file, delimiter=','):\n",
    "    x_cols = (1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16)\n",
    "    y_cols = (0)\n",
    "    \n",
    "    x = np.genfromtxt(file, delimiter=delimiter, skip_header=True, usecols=x_cols)\n",
    "    # visibility 4\n",
    "    x[:,3] = normalize(x[:,3])\n",
    "    # wind 5\n",
    "    x[:,4] = normalize(x[:,4])\n",
    "    # wind_dir, ignore\n",
    "    # x[:,5] = normalize(x[:,5])\n",
    "\n",
    "    y = np.genfromtxt(file, delimiter=delimiter, skip_header=True, usecols=y_cols)\n",
    "    y = np.array([[value] for value in y])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "RecurrentNeuralNetwork instance has no attribute 'test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-36483377b276>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/tiffanybalcarcel/git/RNN_accident_forecast/4hours-test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecurrentNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: RecurrentNeuralNetwork instance has no attribute 'test'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # convert_data(\"./data/4hours.csv\", \"./data/4hours2.csv\")\n",
    "    # convert_data(\"./data/2hours.csv\", \"./data/2hours2.csv\")\n",
    "    train_x, train_y = data_import(\"/Users/tiffanybalcarcel/git/RNN_accident_forecast/4hours-training.csv\")\n",
    "    test_x, test_y = data_import(\"/Users/tiffanybalcarcel/git/RNN_accident_forecast/4hours-test.csv\")\n",
    "    nn = RecurrentNeuralNetwork()\n",
    "    nn.test(train_x, train_y, test_x, test_y, batch_n=1, epochs=8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
